Image Captioning: A confluence on Natural
Language Processing and Computer Vision

[Please click here for paper](https://drive.google.com/file/d/1iEpD2FmewwTxK6yR0C4_ecl-2yZd4-aY/view?usp=sharing)

Project Description:

- Developed models to generate descriptive captions for images and convert them to speech, aiding visually impaired individuals.
- Utilized Flickr 8K datasets to train accurate image captioning models for daily life activities.
- Overcame training time and performance challenges by optimizing GRU layers and dropout values for improved generalization and convergence. 
- Combined CNN feature extraction with GRU-based decoders to generate captions based on image features.
- Preprocessed images and captions, including resizing, normalization, tokenization, integer encoding, and leveraging pre-trained GloVe Word Vectors.
- Validated model performance on real time images.

Applications:

1. Visually Impaired Assistance: Convert image captions to speech, enabling visually impaired individuals to understand their surroundings.
2. Integration with Apple's Measure App: Integrate with Measure app by estimating distances and providing elevation information based on image analysis, aiding visually impaired users in real-life scenarios.
3. Video Summarization: Generate concise summaries of video clips or identify objects and their positions, facilitating efficient video understanding.
4. Domain-Specific Applications: Adapt the model to fashion or food domains, providing detailed information about clothing items or assisting in locating specific food items through image-based searches.
